# Chat Service com IntegraÃ§Ã£o N8N

Este documento descreve as melhorias implementadas no `chat_rag_service.py` para integraÃ§Ã£o com N8N e suporte a mÃºltiplas collections.

## ğŸš€ Novas Funcionalidades

### 1. IntegraÃ§Ã£o com N8N
- **Webhook automÃ¡tico**: O chat service envia automaticamente requisiÃ§Ãµes para o N8N
- **Fallback inteligente**: Se o N8N falhar, usa processamento local
- **ConfiguraÃ§Ã£o flexÃ­vel**: Pode ser habilitado/desabilitado via flag `use_n8n`

### 2. Suporte a MÃºltiplas Collections
- **SeleÃ§Ã£o flexÃ­vel**: UsuÃ¡rio pode escolher uma, vÃ¡rias ou todas as collections
- **Busca abrangente**: Busca documentos em todas as collections selecionadas
- **Metadados detalhados**: Envia informaÃ§Ãµes completas das collections para o N8N

### 3. Compatibilidade Mantida
- **API antiga**: MantÃ©m suporte ao parÃ¢metro `collection_name`
- **MÃ©todos legados**: Preserva mÃ©todos antigos para compatibilidade
- **MigraÃ§Ã£o suave**: TransiÃ§Ã£o transparente para o novo sistema

## ğŸ“‹ Estrutura dos Dados Enviados para N8N

### Payload do Webhook `/webhook/rag-chat`

```json
{
  "message": "Pergunta do usuÃ¡rio",
  "session_id": "uuid-da-sessao",
  "collections": [
    {
      "name": "collection-1",
      "embedding_model": "openai",
      "model_config": {
        "name": "OpenAI Text Embedding",
        "model": "text-embedding-3-small",
        "dimension": 1536,
        "provider": "openai"
      },
      "description": "DescriÃ§Ã£o da collection",
      "document_count": 150,
      "created_at": "2024-01-01T10:00:00",
      "vector_dimension": 1536,
      "model_provider": "openai"
    }
  ],
  "chat_history": [
    {
      "role": "user",
      "content": "Mensagem anterior",
      "timestamp": "2024-01-01T10:00:00"
    }
  ],
  "timestamp": "2024-01-01T10:00:00",
  "source": "rag-demo"
}
```

### Resposta Esperada do N8N

```json
{
  "response": "Resposta gerada pelo N8N",
  "sources": [
    {
      "text": "Texto do documento",
      "score": 0.95,
      "source_collection": "collection-1",
      "metadata": {
        "file_name": "documento.pdf",
        "chunk_index": 0
      }
    }
  ]
}
```

## ğŸ”§ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```env
# N8N Configuration
N8N_WEBHOOK_URL=http://localhost:5678/webhook
N8N_USERNAME=admin
N8N_PASSWORD=admin123
```

### ConfiguraÃ§Ã£o no Docker Compose

O N8N jÃ¡ estÃ¡ configurado no `docker-compose.yml`:

```yaml
n8n:
  container_name: n8n
  image: n8nio/n8n:latest
  ports:
    - "5678:5678"
  environment:
    - N8N_BASIC_AUTH_ACTIVE=true
    - N8N_BASIC_AUTH_USER=admin
    - N8N_BASIC_AUTH_PASSWORD=admin123
```

## ğŸ“ Como Usar

### 1. API REST

#### MÃºltiplas Collections (Novo)
```bash
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Explique processamento de linguagem natural",
    "collection_names": ["nlp-docs", "ai-papers"],
    "session_id": "session-123"
  }'
```

#### Todas as Collections
```bash
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Explique processamento de linguagem natural",
    "session_id": "session-123"
  }'
```

#### Collection Ãšnica (Compatibilidade)
```bash
curl -X POST http://localhost:5000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Explique processamento de linguagem natural",
    "collection_name": "nlp-docs",
    "session_id": "session-123"
  }'
```

### 2. CÃ³digo Python

```python
from src.chat_rag_service import ChatManager

# Inicializar chat manager
chat_manager = ChatManager()

# Criar sessÃ£o
session_id = chat_manager.create_session()

# Chat com mÃºltiplas collections
result = chat_manager.chat(
    session_id=session_id,
    message="Explique machine learning",
    collection_names=["ml-books", "ai-papers"]
)

print(result['response'])
print(f"Collections usadas: {result['collections_used']}")
print(f"Processado por: {result['processed_by']}")  # 'n8n' ou 'local'
```

## ğŸ”„ Fluxo de Processamento

```mermaid
graph TD
    A[Mensagem do UsuÃ¡rio] --> B[Normalizar Collections]
    B --> C[Obter Metadados das Collections]
    C --> D{N8N Habilitado?}
    
    D -->|Sim| E[Enviar para N8N]
    E --> F{N8N Sucesso?}
    F -->|Sim| G[Resposta do N8N]
    F -->|NÃ£o| H[Fallback Local]
    
    D -->|NÃ£o| H[Processamento Local]
    H --> I[Buscar Documentos]
    I --> J[Gerar Resposta]
    
    G --> K[Salvar na SessÃ£o]
    J --> K
    K --> L[Retornar Resultado]
```

## ğŸ› ï¸ ConfiguraÃ§Ã£o do Workflow N8N

### Webhook Node
- **URL**: `/webhook/rag-chat`
- **Method**: POST
- **Response**: JSON

### Exemplo de Workflow BÃ¡sico

1. **Webhook Trigger**: Recebe dados do chat
2. **Code Node**: Processa collections e mensagem
3. **HTTP Request**: Chama APIs externas se necessÃ¡rio
4. **Response Node**: Retorna resposta formatada

### Template de CÃ³digo N8N

```javascript
// CÃ³digo de exemplo para processar no N8N
const collections = $json.collections;
const message = $json.message;

// LÃ³gica personalizada baseada nas collections
if (collections.some(c => c.name.includes('legal'))) {
  // Processamento especÃ­fico para documentos legais
} else if (collections.some(c => c.name.includes('technical'))) {
  // Processamento especÃ­fico para documentos tÃ©cnicos
}

return {
  response: "Resposta processada pelo N8N",
  sources: []
};
```

## ğŸ› SoluÃ§Ã£o de Problemas

### N8N NÃ£o Responde
- Verificar se o N8N estÃ¡ rodando: `http://localhost:5678`
- Verificar logs do container: `docker logs n8n`
- Testar webhook manualmente

### Collections NÃ£o Encontradas
- Verificar se as collections existem no Qdrant
- Verificar se os nomes estÃ£o corretos
- Usar `get_collections()` para listar disponÃ­veis

### Fallback Local
- Verificar configuraÃ§Ã£o do N8N
- Verificar conectividade de rede
- Logs mostrarÃ£o quando fallback Ã© usado

## ğŸ“Š Monitoramento

### Logs Importantes
```
âœ… Collection 'nlp-docs' criada com modelo 'openai'
âš ï¸ N8N falhou, usando processamento local como fallback  
ğŸ“Š Processamento por N8N concluÃ­do em 1.2s
```

### MÃ©tricas
- Tempo de resposta N8N vs Local
- Taxa de sucesso do N8N
- Collections mais utilizadas
- SessÃµes ativas

## ğŸ”— ReferÃªncias

- [ConfiguraÃ§Ã£o N8N](../workflows_n8n.md)
- [API Documentation](../README.md#apis-disponÃ­veis)
- [Vector Store](./VECTOR_STORE.md) 